{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"570c24f2-126a-4fd3-bae2-e8247646f36d","_uuid":"118c9d31c593676aaf77c8975339e52d7cb65cdf"},"source":["**Predicting IDC in Breast Cancer Histology Images**\n","\n","Breast cancer is the most common form of cancer in women, and invasive ductal carcinoma (IDC) is the most common form of breast cancer. Accurately identifying and categorizing breast cancer subtypes is an important clinical task, and automated methods can be used to save time and reduce error.\n","\n","The goal of this script is to identify IDC when it is present in otherwise unlabeled histopathology images. The dataset consists of 277,524 50x50 pixel RGB digital image patches that were derived from 162 H&E-stained breast histopathology samples. These images are small patches that were extracted from digital images of breast tissue samples. The breast tissue contains many cells but only some of them are cancerous. Patches that are labeled \"1\" contain cells that are characteristic of invasive ductal carcinoma. For more information about the data, see https://www.ncbi.nlm.nih.gov/pubmed/27563488 and http://spie.org/Publications/Proceedings/Paper/10.1117/12.2043872.\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"eb849bd9-7894-4fd3-b55d-4d0a77c9161c","_uuid":"debe60106fe79d3b2316308fd11f3d2399255c61"},"source":["_Step 1: Import Modules_\n"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"bb9fe3ef-104a-4a98-9f87-b65906acf50f","_kg_hide-input":true,"_uuid":"5a9827f8d703a8741175d1e7df3121632715bdd8","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","from glob import glob\n","import itertools\n","import fnmatch\n","import random\n","import matplotlib.pylab as plt\n","import seaborn as sns\n","import cv2\n","from scipy.misc import imresize, imread\n","import sklearn\n","from sklearn import model_selection\n","from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\n","from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","import keras\n","from keras import backend as K\n","from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils.np_utils import to_categorical\n","from keras.models import Sequential, model_from_json\n","from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n","from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"_cell_guid":"4c6bd2df-2a43-4604-b407-ba81c8c3939b","_uuid":"540f3c39324580297bcff94b4c4cfc0c5bb45b5f"},"source":["_Step 2: Explore Data_\n"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"765908c1-86cc-41df-8479-a39174231237","_uuid":"1978266e1e2fe5d6eb9bdc17deb0d309441065a2","trusted":true},"outputs":[],"source":["imagePatches = glob('/kaggle/input/IDC_regular_ps50_idx5/**/*.png', recursive=True)\n","for filename in imagePatches[0:10]:\n","    print(filename)"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"0fd6c75a-b439-455c-ba85-24aa9d83da5b","_uuid":"1d105b2c6fff7ddfd3120215ea7f77723e360179","trusted":true},"outputs":[],"source":["image_name = \"/kaggle/input/IDC_regular_ps50_idx5/9135/1/9135_idx5_x1701_y1851_class1.png\" #Image to be used as query\n","def plotImage(image_location):\n","    image = cv2.imread(image_name)\n","    image = cv2.resize(image, (50,50))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)); plt.axis('off')\n","    return\n","plotImage(image_name)"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"cfc417f1-c12a-42df-b264-c4e7e6e79da8","_uuid":"f9d9578ed454625dbe08a3185865cc3ae556b993","trusted":true},"outputs":[],"source":["# Plot Multiple Images\n","bunchOfImages = imagePatches\n","i_ = 0\n","plt.rcParams['figure.figsize'] = (10.0, 10.0)\n","plt.subplots_adjust(wspace=0, hspace=0)\n","for l in bunchOfImages[:25]:\n","    im = cv2.imread(l)\n","    im = cv2.resize(im, (50, 50)) \n","    plt.subplot(5, 5, i_+1) #.set_title(l)\n","    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n","    i_ += 1"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"f010fda5-40f0-47ce-89c0-40d21a754f59","_uuid":"10cc771383f08fd404419bccaa00ed9ad99cd0e2","trusted":true},"outputs":[],"source":["def randomImages(a):\n","    r = random.sample(a, 4)\n","    plt.figure(figsize=(16,16))\n","    plt.subplot(131)\n","    plt.imshow(cv2.imread(r[0]))\n","    plt.subplot(132)\n","    plt.imshow(cv2.imread(r[1]))\n","    plt.subplot(133)\n","    plt.imshow(cv2.imread(r[2])); \n","randomImages(imagePatches)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"5f695df0-da48-4cc5-93a0-dcb7a82d21a3","_uuid":"c88fc872e6af3918192df09635e88904145761a2"},"source":["_Step 3: Preprocess Data_\n"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"939bc134-6122-4d4d-aa6c-89a47318896d","_uuid":"aae6a2ec2ab20bd94422e29b147a45a880fb480a","trusted":true},"outputs":[],"source":["patternZero = '*class0.png'\n","patternOne = '*class1.png'\n","classZero = fnmatch.filter(imagePatches, patternZero)\n","classOne = fnmatch.filter(imagePatches, patternOne)\n","print(\"IDC(-)\\n\\n\",classZero[0:5],'\\n')\n","print(\"IDC(+)\\n\\n\",classOne[0:5])"]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"f62e9e56-6564-4376-845f-284f624fa932","_uuid":"69640054f59133ebe8dfa06612f3c14383916e90","collapsed":true,"trusted":true},"outputs":[],"source":["def proc_images(lowerIndex,upperIndex):\n","    \"\"\"\n","    Returns two arrays: \n","        x is an array of resized images\n","        y is an array of labels\n","    \"\"\" \n","    x = []\n","    y = []\n","    WIDTH = 50\n","    HEIGHT = 50\n","    for img in imagePatches[lowerIndex:upperIndex]:\n","        full_size_image = cv2.imread(img)\n","        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n","        if img in classZero:\n","            y.append(0)\n","        elif img in classOne:\n","            y.append(1)\n","        else:\n","            return\n","    return x,y"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"3bf67ef8-5613-4862-bc46-0106d1880981","_uuid":"2b8fd5414423f1e7ff7da620d8672bb496a9ef57","collapsed":true,"trusted":true},"outputs":[],"source":["X,Y = proc_images(0,90000)\n","df = pd.DataFrame()\n","df[\"images\"]=X\n","df[\"labels\"]=Y\n","X2=df[\"images\"]\n","Y2=df[\"labels\"]\n","X2=np.array(X2)\n","imgs0=[]\n","imgs1=[]\n","imgs0 = X2[Y2==0] # (0 = no IDC, 1 = IDC)\n","imgs1 = X2[Y2==1] "]},{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"b3c1681f-7576-4b3d-ad49-7832e3bcf209","_uuid":"5660e633007abaeda0a4698b8bfacf55d9552ab4","trusted":true},"outputs":[],"source":["def describeData(a,b):\n","    print('Total number of images: {}'.format(len(a)))\n","    print('Number of IDC(-) Images: {}'.format(np.sum(b==0)))\n","    print('Number of IDC(+) Images: {}'.format(np.sum(b==1)))\n","    print('Percentage of positive images: {:.2f}%'.format(100*np.mean(b)))\n","    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))\n","describeData(X2,Y2)"]},{"cell_type":"code","execution_count":10,"metadata":{"_cell_guid":"0c3b967b-674c-4efa-b59e-56772166ef41","_uuid":"9eed051f46211121a7add96c9cf86165340a7e28","trusted":true},"outputs":[],"source":["dict_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n","print(df.head(10))\n","print(\"\")\n","print(dict_characters)"]},{"cell_type":"code","execution_count":11,"metadata":{"_cell_guid":"d72d8a7d-7234-4a68-92f9-8f3578e08e36","_uuid":"3836924a638d95d90d85a02829bd85933f3c495f","trusted":true},"outputs":[],"source":["def plotOne(a,b):\n","    \"\"\"\n","    Plot one numpy array\n","    \"\"\"\n","    plt.subplot(1,2,1)\n","    plt.title('IDC (-)')\n","    plt.imshow(a[0])\n","    plt.subplot(1,2,2)\n","    plt.title('IDC (+)')\n","    plt.imshow(b[0])\n","plotOne(imgs0, imgs1) "]},{"cell_type":"code","execution_count":12,"metadata":{"_cell_guid":"389ea274-9f97-45e6-a99f-d3362412e721","_uuid":"c83c02425f516da672e7957f0cd42ecc72dce981","trusted":true},"outputs":[],"source":["def plotTwo(a,b): \n","    \"\"\"\n","    Plot a bunch of numpy arrays sorted by label\n","    \"\"\"\n","    for row in range(3):\n","        plt.figure(figsize=(20, 10))\n","        for col in range(3):\n","            plt.subplot(1,8,col+1)\n","            plt.title('IDC (-)')\n","            plt.imshow(a[0+row+col])\n","            plt.axis('off')       \n","            plt.subplot(1,8,col+4)\n","            plt.title('IDC (+)')\n","            plt.imshow(b[0+row+col])\n","            plt.axis('off')\n","plotTwo(imgs0, imgs1) "]},{"cell_type":"markdown","metadata":{"_cell_guid":"254e9903-c303-46cd-bde9-0d3b412e6cdb","_uuid":"4d584d18cb934f1cf025e9bbb6d6cb8c03542494"},"source":["The data is scaled from 0 to 256 but we want it to be scaled from 0 to 1. This will make the data compatible with a wide variety of different classification algorithms. We also want to set aside 20% of the data for testing. This will make the trained model less prone to overfitting. And finally, we will use an oversampling strategy to deal with the imbalanced class sizes.\n"]},{"cell_type":"code","execution_count":13,"metadata":{"_cell_guid":"c5d01476-b570-4fb4-8ebb-1af69f3e215e","_uuid":"23ca1626461e4749493064070986a075f8317539","trusted":true},"outputs":[],"source":["def plotHistogram(a):\n","    \"\"\"\n","    Plot histogram of RGB Pixel Intensities\n","    \"\"\"\n","    plt.figure(figsize=(10,5))\n","    plt.subplot(1,2,1)\n","    plt.imshow(a)\n","    plt.axis('off')\n","    plt.title('IDC(+)' if Y[1] else 'IDC(-)')\n","    histo = plt.subplot(1,2,2)\n","    histo.set_ylabel('Count')\n","    histo.set_xlabel('Pixel Intensity')\n","    n_bins = 30\n","    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5);\n","    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5);\n","    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5);\n","plotHistogram(X2[100])"]},{"cell_type":"code","execution_count":14,"metadata":{"_cell_guid":"9f9e4c80-a8e0-47ac-957b-22231b1e9fca","_uuid":"ae82d3f7ec59d7d112a8dd9ed1b8121a4792a1b0","trusted":true},"outputs":[],"source":["X=np.array(X)\n","X=X/255.0\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n","\n","# Reduce Sample Size for DeBugging\n","X_train = X_train[0:300000] \n","Y_train = Y_train[0:300000]\n","X_test = X_test[0:300000] \n","Y_test = Y_test[0:300000]\n","\n","print(\"Training Data Shape:\", X_train.shape)\n","print(\"Testing Data Shape:\", X_test.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"_cell_guid":"b07de5e9-53dd-49e5-9da3-778bc9eb9b17","_uuid":"5d808c28fb0f9aaa0364d8b62d11fc1f2810c2c8","trusted":true},"outputs":[],"source":["plotHistogram(X_train[100])"]},{"cell_type":"code","execution_count":16,"metadata":{"_cell_guid":"a23e5463-5d12-43c8-8a3a-eb7dcfecdf6b","_uuid":"447f1371f137cf51962a0f32171d44a3080a694c","collapsed":true,"trusted":true},"outputs":[],"source":["# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n","Y_trainHot = to_categorical(Y_train, num_classes = 2)\n","Y_testHot = to_categorical(Y_test, num_classes = 2)"]},{"cell_type":"code","execution_count":17,"metadata":{"_cell_guid":"ab055bcf-2a2c-4645-b043-45d28ddcc782","_uuid":"1c05f8d5a5ada31b3741944ac02d480c2b39619f","trusted":true},"outputs":[],"source":["lab = df['labels']\n","dist = lab.value_counts()\n","sns.countplot(lab)\n","print(dict_characters)"]},{"cell_type":"code","execution_count":18,"metadata":{"_cell_guid":"06cb3ea4-371a-4971-9449-dc726f06e16b","_uuid":"5d3087f0dfe874a591449b9d5f27da138f42f0c6","trusted":true},"outputs":[],"source":["# Deal with imbalanced class sizes below\n","# Make Data 1D for compatability upsampling methods\n","X_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\n","X_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\n","X_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\n","X_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\n","#print(\"X_train Shape: \",X_train.shape)\n","#print(\"X_test Shape: \",X_test.shape)\n","#print(\"X_trainFlat Shape: \",X_trainFlat.shape)\n","#print(\"X_testFlat Shape: \",X_testFlat.shape)\n","\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler\n","#ros = RandomOverSampler(ratio='auto')\n","ros = RandomUnderSampler(ratio='auto')\n","X_trainRos, Y_trainRos = ros.fit_sample(X_trainFlat, Y_train)\n","X_testRos, Y_testRos = ros.fit_sample(X_testFlat, Y_test)\n","\n","# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n","Y_trainRosHot = to_categorical(Y_trainRos, num_classes = 2)\n","Y_testRosHot = to_categorical(Y_testRos, num_classes = 2)\n","#print(\"X_train: \", X_train.shape)\n","#print(\"X_trainFlat: \", X_trainFlat.shape)\n","#print(\"X_trainRos Shape: \",X_trainRos.shape)\n","#print(\"X_testRos Shape: \",X_testRos.shape)\n","#print(\"Y_trainRosHot Shape: \",Y_trainRosHot.shape)\n","#print(\"Y_testRosHot Shape: \",Y_testRosHot.shape)\n","\n","for i in range(len(X_trainRos)):\n","    height, width, channels = 50,50,3\n","    X_trainRosReshaped = X_trainRos.reshape(len(X_trainRos),height,width,channels)\n","#print(\"X_trainRos Shape: \",X_trainRos.shape)\n","#print(\"X_trainRosReshaped Shape: \",X_trainRosReshaped.shape)\n","\n","for i in range(len(X_testRos)):\n","    height, width, channels = 50,50,3\n","    X_testRosReshaped = X_testRos.reshape(len(X_testRos),height,width,channels)\n","#print(\"X_testRos Shape: \",X_testRos.shape)\n","#print(\"X_testRosReshaped Shape: \",X_testRosReshaped.shape)\n","\n","dfRos = pd.DataFrame()\n","dfRos[\"labels\"]=Y_trainRos\n","labRos = dfRos['labels']\n","distRos = lab.value_counts()\n","sns.countplot(labRos)\n","print(dict_characters)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"11ec5cdf-44ad-4bf6-8975-4fa4682d5e2a","_uuid":"9265cdcdeb26c3169db18392ce1603885129a130"},"source":["_Step 4: Define Helper Functions for the Classification Task_\n"]},{"cell_type":"code","execution_count":19,"metadata":{"_cell_guid":"5a0e446b-a55a-4933-b4a7-198da1669545","_uuid":"ec338837016d3d5222e98a10331b1b2de457db34","trusted":true},"outputs":[],"source":["from sklearn.utils import class_weight\n","class_weight = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\n","print(\"Old Class Weights: \",class_weight)\n","from sklearn.utils import class_weight\n","class_weight2 = class_weight.compute_class_weight('balanced', np.unique(Y_trainRos), Y_trainRos)\n","print(\"New Class Weights: \",class_weight2)"]},{"cell_type":"code","execution_count":20,"metadata":{"_cell_guid":"137bc037-a8a4-4dac-aecd-62d6efc6c127","_uuid":"4a883a6aaddd3261a630af0f12ed7e542da3eb3f","collapsed":true,"trusted":true},"outputs":[],"source":["# Helper Functions  Learning Curves and Confusion Matrix\n","\n","class MetricsCheckpoint(Callback):\n","    \"\"\"Callback that saves metrics after each epoch\"\"\"\n","    def __init__(self, savepath):\n","        super(MetricsCheckpoint, self).__init__()\n","        self.savepath = savepath\n","        self.history = {}\n","    def on_epoch_end(self, epoch, logs=None):\n","        for k, v in logs.items():\n","            self.history.setdefault(k, []).append(v)\n","        np.save(self.savepath, self.history)\n","\n","def plotKerasLearningCurve():\n","    plt.figure(figsize=(10,5))\n","    metrics = np.load('logs.npy')[()]\n","    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n","    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n","        l = np.array(metrics[k])\n","        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n","        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n","        y = l[x]\n","        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n","        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n","    plt.legend(loc=4)\n","    plt.axis([0, None, None, None]);\n","    plt.grid()\n","    plt.xlabel('Number of epochs')\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    plt.figure(figsize = (5,5))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","def plot_learning_curve(history):\n","    plt.figure(figsize=(8,8))\n","    plt.subplot(1,2,1)\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.savefig('./accuracy_curve.png')\n","    #plt.clf()\n","    # summarize history for loss\n","    plt.subplot(1,2,2)\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.savefig('./loss_curve.png')"]},{"cell_type":"markdown","metadata":{"_cell_guid":"0fe72b01-0848-4ac9-b4b8-a2d212cfcc2d","_uuid":"4524ae34f83914f75a2da05afba664cf7f0ea505"},"source":["_Step 5: Evaluate Classification Models_\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"fde814f1-38f0-402f-81da-c7f899791b4b","_uuid":"5fb738a2cb7f08a57ca493c948a44d9df975d3d7"},"source":["In a previous kernel I evaluated a number of different classification algorithms while using an abbreviated form of this same dataset. To see how and why I chose the model that I use below, please see the following link: https://www.kaggle.com/paultimothymooney/predicting-idc-in-breast-cancer-histology-images/\n"]},{"cell_type":"code","execution_count":21,"metadata":{"_cell_guid":"47acf66e-5542-4f73-908c-11f76ed8becf","_uuid":"6d7e57d88e5578aea8b0b8f397d2a689e9c74de0","trusted":true},"outputs":[],"source":["def runKerasCNNAugment(a,b,c,d,e,f):\n","    \"\"\"\n","    Run Keras CNN: https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n","    \"\"\"\n","    batch_size = 128\n","    num_classes = 2\n","    epochs = 8\n","#     img_rows, img_cols = a.shape[1],a.shape[2]\n","    img_rows,img_cols=50,50\n","    input_shape = (img_rows, img_cols, 3)\n","    model = Sequential()\n","    model.add(Conv2D(32, kernel_size=(3, 3),\n","                     activation='relu',\n","                     input_shape=input_shape,strides=e))\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    model.compile(loss=keras.losses.categorical_crossentropy,\n","                  optimizer=keras.optimizers.Adadelta(),\n","                  metrics=['accuracy'])\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n","        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=True)  # randomly flip images\n","    history = model.fit_generator(datagen.flow(a,b, batch_size=32),\n","                        steps_per_epoch=len(a) / 32, epochs=epochs,class_weight=f, validation_data = [c, d],callbacks = [MetricsCheckpoint('logs')])\n","    score = model.evaluate(c,d, verbose=0)\n","    print('\\nKeras CNN #1C - accuracy:', score[1],'\\n')\n","    y_pred = model.predict(c)\n","    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n","    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')    \n","    Y_pred_classes = np.argmax(y_pred,axis=1) \n","    Y_true = np.argmax(d,axis=1) \n","    plotKerasLearningCurve()\n","    plt.show()  \n","    plot_learning_curve(history)\n","    plt.show()\n","    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n","    plot_confusion_matrix(confusion_mtx, classes = list(dict_characters.values())) \n","    plt.show()\n","runKerasCNNAugment(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,2,class_weight2)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a03f19fc-05c4-4f8a-8e0b-a921c781ff10","_uuid":"7bc3bc872c444fe5990aa365a832b6dc9c9bdad8"},"source":["Next I will try one more time but without the undersampling step.\n"]},{"cell_type":"code","execution_count":22,"metadata":{"_cell_guid":"97db66e5-0fc8-4e1d-bfc0-179c3391f08f","_uuid":"9854e5bb4554a4bea7d59a37ec6d4a24ce141fc0","collapsed":true,"scrolled":false,"trusted":true},"outputs":[],"source":["#runKerasCNNAugment(X_train, Y_trainHot, X_test, Y_testHot,2,class_weight)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"3e4418ff-dabc-46b4-8fa9-7daaab1402a7","_uuid":"069b85a95cbc0c4aa7e71b64ad9ef3c8aebf4373"},"source":["90+% accuracy is pretty good! And it does not look too be to overfit or too biased based off of the learning curve and confusion matrix. In the future, I will improve the score by optimizing the data augmentation step as well as the network architecture.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}
